{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optimize2! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using GaussianProcesses, PGFPlots, SumProductNetworks\n",
    "using StatsFuns, Distributions, ProgressMeter#, MultivariateStats\n",
    "import SumProductNetworks.add!\n",
    "\n",
    "include(\"utilFunctions.jl\")\n",
    "include(\"dataTypes.jl\")\n",
    "include(\"dataTypeUtilFunctions.jl\")\n",
    "include(\"computationFunctions.jl\")\n",
    "include(\"regionGraph.jl\")\n",
    "include(\"regionGraphUtils.jl\")\n",
    "include(\"gpUtils.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo if wifi access\n",
    "# Pkg.add(\"MultivariateStats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = readdlm(\"../data/kin40k/kin40k_train_data.asc\");\n",
    "ytrain = readdlm(\"../data/kin40k/kin40k_train_labels.asc\");\n",
    "\n",
    "Xtest = readdlm(\"../data/kin40k/kin40k_test_data.asc\");\n",
    "ytest = readdlm(\"../data/kin40k/kin40k_test_labels.asc\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: (10000, 8)\n",
      "size of test set: (30000, 8)\n"
     ]
    }
   ],
   "source": [
    "println(\"size of training set: \", size(Xtrain))\n",
    "println(\"size of test set: \", size(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in expert: 0\n",
      "Samples in expert: 2507\n",
      "Samples in expert: 2600\n",
      "Samples in expert: 5107\n",
      "Samples in expert: 0\n",
      "Samples in expert: 1264\n",
      "Samples in expert: 1291\n",
      "Samples in expert: 2555\n",
      "Samples in expert: 0\n",
      "Samples in expert: 1243\n",
      "Samples in expert: 1309\n",
      "Samples in expert: 2552\n",
      "Samples in expert: 0\n",
      "Samples in expert: 0\n",
      "Samples in expert: 2463\n",
      "Samples in expert: 2430\n",
      "Samples in expert: 4893\n",
      "Samples in expert: 0\n",
      "Samples in expert: 1182\n",
      "Samples in expert: 1203\n",
      "Samples in expert: 2385\n",
      "Samples in expert: 0\n",
      "Samples in expert: 1281\n",
      "Samples in expert: 1227\n",
      "Samples in expert: 2508\n",
      "Samples in expert: 0\n"
     ]
    }
   ],
   "source": [
    "global gID = 1\n",
    "\n",
    "(N, D) = size(Xtrain)\n",
    "\n",
    "numSums = 1\n",
    "meanFunction = MeanZero();\n",
    "kernelFunctions = [LinArd(ones(D)*log(5.0)), SE(-1., 0.), SEArd(ones(D)*log(5.0), log(1.0))]\n",
    "\n",
    "kernelPriors = []\n",
    "\n",
    "noise = -1.;\n",
    "\n",
    "# data range\n",
    "minX = vec(minimum(Xtrain, 1)) - 0.1\n",
    "maxX = vec(maximum(Xtrain, 1)) + 0.1\n",
    "\n",
    "# split size\n",
    "δ = (maxX - minX) ./ 2\n",
    "\n",
    "# maximum depth\n",
    "max_depth = 3\n",
    "min_samples = 200\n",
    "\n",
    "overlap = 0.0\n",
    "\n",
    "(rootRegion, sumRegions, gpRegions, allPartitions) = poonDomingos_ND(δ, minX, maxX, max_depth, min_samples, Xtrain);\n",
    "\n",
    "RegionIDs = Dict(r[2] => r[1] for r in enumerate(union(sumRegions, gpRegions)));\n",
    "PartitionIDS = Dict(p[2] => p[1] + maximum(values(RegionIDs)) for p in enumerate(allPartitions));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check helper structures\n",
    "for p in allPartitions\n",
    "    @assert haskey(PartitionIDS, p)\n",
    "    @assert length(p.regions) == 2\n",
    "    for r in p.regions\n",
    "        @assert haskey(RegionIDs, r)\n",
    "        if isa(r, NDSumRegion)\n",
    "            @assert length(r.partitions) >= 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# check for loops\n",
    "function findPartition(p, r::NDSumRegion, depth, maxdepth)\n",
    "    \n",
    "    @assert depth < maxdepth\n",
    "    \n",
    "    if p in r.partitions\n",
    "        return true\n",
    "    end\n",
    "    \n",
    "    found = false\n",
    "    for pp in r.partitions\n",
    "        found |= findPartition(p, pp, depth + 1, maxdepth)\n",
    "    end\n",
    "    \n",
    "    return found\n",
    "end\n",
    "\n",
    "function findPartition(p, r::NDGPRegion, depth, maxdepth)\n",
    "    return false\n",
    "end\n",
    "\n",
    "function findPartition(p, pp::NDSplitPartition, depth, maxdepth)\n",
    "    found = false\n",
    "    for r in pp.regions\n",
    "        found |= findPartition(p, r, depth, maxdepth)\n",
    "    end\n",
    "    \n",
    "    return found\n",
    "end\n",
    "\n",
    "for p in allPartitions\n",
    "    for r in p.regions\n",
    "        @assert !findPartition(p, r, 0, 4)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_ = convertToSPN_ND(rootRegion, gpRegions, RegionIDs, PartitionIDS, Xtrain, ytrain[:,1], meanFunction, \n",
    "                    kernelFunctions, kernelPriors, noise; overlap = overlap, do_mcmc = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill!(root_.prior_weights, 1. / length(root_))\n",
    "fill!(root_.posterior_weights, 1. / length(root_))\n",
    "\n",
    "spn_update!(root_)\n",
    "spn_posterior(root_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_fixed = predict_spn!(root_, Xtest);\n",
    "rmse_spn_fixed = sqrt(mean((yhat_fixed .- ytest).^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpnodes = unique(filter(n -> isa(n, GPLeaf), SumProductNetworks.getOrderedNodes(root_)));\n",
    "map(gnode -> optimize2!(gnode.gp, mean = false, kern = true, noise = true, lik=false), gpnodes);\n",
    "\n",
    "fill!(root_.prior_weights, 1. / length(root_))\n",
    "fill!(root_.posterior_weights, 1. / length(root_))\n",
    "\n",
    "spn_update!(root_)\n",
    "spn_posterior(root_)\n",
    "\n",
    "yhat_opt = predict_spn!(root_, Xtest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "6.358368481348373"
      ],
      "text/plain": [
       "6.358368481348373"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_spn_opt = sqrt(mean((yhat_opt .- ytest).^2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
